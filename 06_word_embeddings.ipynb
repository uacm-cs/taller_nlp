{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings: FastText\n",
    "\n",
    "- #### **Word embeddings** con **Word2Vec** representan palabras como vectores densos.\n",
    "- #### Captan relaciones semánticas entre palabras basándose en su contexto.\n",
    "- #### Palabras con significados similares están más cercanas en el espacio vectorial.\n",
    "- #### Se entrenan usando dos enfoques principales: **Skip-gram** y **CBOW**.\n",
    "- #### Word2Vec se utiliza en tareas como clasificación, análisis de sentimientos y traducción automática.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [https://fasttext.cc](https://fasttext.cc)\n",
    "\n",
    "## Modelo pre-entrenados para el idioma español\n",
    "\n",
    "### [https://fasttext.cc/docs/en/crawl-vectors.html](https://fasttext.cc/docs/en/crawl-vectors.html#models)\n",
    "\n",
    "\n",
    "## Modelo pre-entrenados para diferentes regiones del idioma español\n",
    "\n",
    "### [https://ingeotec.github.io/regional-spanish-models](https://ingeotec.github.io/regional-spanish-models/#resources)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación del paquete FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar el modelo pre-entrenado para la codificación de word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "# Descargar el modelo para el español de la página de FastText\n",
    "ft = fasttext.load_model('./data/cc.es.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificar oraciones en su forma de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = ft.get_sentence_vector(\"hola me siento muy feliz\")\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de las palabras vecinas más cercanas basadas en vectores densos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.get_nearest_neighbors(\"mareado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones con vectores semánticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= (ft.get_word_vector(\"rey\") - ft.get_word_vector(\"hombre\")) + ft.get_word_vector(\"mujer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones con vectores semánticos: Analogías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogia = ft.get_analogies(\"rey\",\"hombre\", \"mujer\")\n",
    "print(analogia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando vectores semánticamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener el vocabulario de los vectores pre-entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ft.get_words(on_unicode_error=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular el word embeddings para cada palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "frame_words= pd.DataFrame({\"word\": words})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_words[\"word_embed\"] = frame_words[\"word\"].map(lambda x: ft.get_sentence_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construye la matriz de vectores densos para todo el vocabulario y poder hacer comparaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "_VECS = np.vstack(frame_words[\"word_embed\"].to_numpy() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compara semánticamente el vector X contra todo el vocabulario pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "res = cosine_similarity([X], _VECS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El valor resultante es una matriz de 1 elemento contra todos los elementos del vocabulario\n",
    "print(res.shape)\n",
    "print(res.ndim)\n",
    "# cada elemento es el resultado de la similitud coseno entre X y el elemento en esa posición)\n",
    "# se muestran los primeros 5 elementos de la comparación\n",
    "print(res[0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraer los indices de los valores máximos para la similitud coseno "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordena ascendentemente los resultados de acuerdo a las similitud obtenida\n",
    "indx = np.argsort(res[0])[-10:]\n",
    "print(indx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraer las palabras asociadas a los vectores más similares al vector X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indx[::-1]:\n",
    "    print(frame_words.word.loc[i])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "877a00d7f0fb9e274b8a508beb31c57725cc83104bb2b7e975457837e848a634"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('TF': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
