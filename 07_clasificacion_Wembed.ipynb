{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de Textos con Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/fig-diagrama-clasificador2.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cargar el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "\n",
    "dataset = pd.read_json(\"./data/data_emotions_es.json\", lines=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cargar modelo de vectores pre-entrenados de Word Embeddings: FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Descargar el modelo para el español de la página de FastText\n",
    "\n",
    "# cambiar la ruta del modelo preentrenado\n",
    "ft = fasttext.load_model('./data/cc.es.300.bin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transformar el texto de entrenamiento en un vector denso: 300 dimensiones definido por FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset[\"text_embed\"] = dataset[\"text\"].map(lambda x: ft.get_sentence_vector(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Crear la matriz de vectores y etiquetas para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Cada renglón representa un documento codificado en un texto de embeddings\n",
    "X = np.vstack(dataset['text_embed'].to_numpy())\n",
    "Y = dataset['klass'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparar los conjuntos de datos  (datasets) para entrenamiento y para probar el rendimiento del clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en conjunto de entrenamiento (80%) y conjunto de pruebas (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "# Normalizar las etiquetas a una codificación ordinal para entrada del clasificador\n",
    "Y_encoded= le.fit_transform(Y)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test =  train_test_split(X, Y_encoded, test_size=0.2, stratify=Y_encoded, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Entrenar al clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos LinearSVC del paquete sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clasificador_svc = LinearSVC(random_state=42)\n",
    "\n",
    "# Entrenamos al clasificador\n",
    "\n",
    "clasificador_svc.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción de los datos del conjuntos de prueba con el modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clasificador_svc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspección de los resultados de los primeros N ejemplos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"textos: \")\n",
    "print(dataset.text.loc[:5])\n",
    "print(\"clase esperada: \",Y_test[:5])\n",
    "print(\"clase predicha: \", y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar la predicción de la clase original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obten las primeras N predicciones\n",
    "\n",
    "print(\"textos: \")\n",
    "print(dataset.text.loc[:5])\n",
    "print(\"clase esperada: \",le.inverse_transform(Y_test[:5]))\n",
    "print(\"clase predicha: \", le.inverse_transform(y_pred[:5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluando el desempeño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de Evaluación\n",
    " - #### Las métricas precisión, recall y F1 son fundamentales para evaluar el rendimiento de un clasificador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$$ Accuracy = \\frac{total~ TP + total~TN}{total~muestras} $$\n",
    "\n",
    "$$ Precision_c = \\frac{ TP_c}{TP_c + FP_c} $$\n",
    "\n",
    "$$ Recall_c = \\frac{ TP_c}{TP_c + FN_c} $$\n",
    "\n",
    "$$ F1-score_c= 2 \\times \\frac{ Precision_c \\times Recall_c}{Precision_c + Recall_c} $$\n",
    "\n",
    "$$ macro-F1-score= \\frac{ 1 }{|Clases|} \\sum{F1-score_c} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para la clase 0, la precisión es la siguiente\n",
    "tp= 77\n",
    "fp = 28+17+21\n",
    "tp/(tp + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "print(\"P=\", precision_score(Y_test, y_pred, average='macro'))\n",
    "print(\"R=\", recall_score(Y_test, y_pred, average='macro'))\n",
    "print(\"F1=\", f1_score(Y_test, y_pred, average='macro'))\n",
    "print(\"Acc=\", accuracy_score(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspección del desempeño por clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, y_pred, digits=4, zero_division='warn'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Guadar el modelo para despliegue de la aplicación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se recomienda generar un módulo para el despliegue del modelo (Por ejemplo clasificadorembeddingsTODO.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clasificadorembeddingsTODO import ClasificadorEmbeddignsTODO\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_json(\"./data/data_emotions_es.json\", lines=True)\n",
    "\n",
    "# Descargar el modelo para el español de la página de FastText\n",
    "ft = fasttext.load_model('/Volumes/data/temp/cc.es.300.bin')\n",
    "\n",
    "# Crear los vectores de embeddings\n",
    "dataset[\"text_embed\"] = dataset[\"text\"].map(lambda x: ft.get_sentence_vector(x))\n",
    "\n",
    "# Cada renglón representa un documento codificado en un texto de embeddings\n",
    "X = np.vstack(dataset['text_embed'].to_numpy())\n",
    "Y = dataset['klass'].to_numpy()\n",
    "\n",
    "\n",
    "# Dividir el conjunto de datos en conjunto de entrenamiento (80%) y conjunto de pruebas (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "# Normalizar las etiquetas a una codificación ordinal para entrada del clasificador\n",
    "Y_encoded= le.fit_transform(Y)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test =  train_test_split(X, Y_encoded, test_size=0.2, stratify=Y_encoded, random_state=42)\n",
    "\n",
    "\n",
    "clasificador_svc = ClasificadorEmbeddingsTODO(embeddings_model=ft)\n",
    "clasificador_svc.setLabelEncoder(le)\n",
    "clasificador_svc.fit(X_train, Y_train)\n",
    "\n",
    "# guardar el modelo de clasificación\n",
    "with open('./modelos/modelo_embeddings_svc.pkl','wb') as file:\n",
    "    pickle.dump(clasificador_svc, file)\n",
    "    \n",
    "print(clasificador_svc.predict([X_test[0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taller_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
